{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker - Bring Your Own Model (Deploy)\n",
    "## MXNet + Gluon 編\n",
    "\n",
    "MXNet の Gluon API では、Deep Learning の実装を簡単にするだけでなく、すでに学習済みのモデルも提供しています。学習済みのモデルを使うことによって、ユーザは学習を行うことなく、機械学習を利用することができます。Gluon では、コンピュータービジョンのための [GluonCV](https://gluon-cv.mxnet.io/)、自然言語処理のための [GluonNLP](https://gluon-nlp.mxnet.io/)、時系列データ予測のための [GluonTS](https://gluon-ts.mxnet.io/) を提供しています。\n",
    "\n",
    "このノートブックでは、GluonCV を利用して学習済みのモデルを取得し、そのモデルをデプロイするための実装を行います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.学習済みのモデルのダウンロード\n",
    "### GluonCVのダウンロード\n",
    "デプロイする学習済みのモデルを取得するために、GluonCV をノートブックインスタンスにダウンロードします。`!`を冒頭に入れてインストールコマンドを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルのダウンロード・保存\n",
    "\n",
    "GluonCV を import して、`model_zoo.get_model`を行うことでモデルを読み込むことができます。`pretrained=True` と指定することで、学習済みモデルを利用することができます。利用可能なモデルについては、https://gluon-cv.mxnet.io/api/model_zoo.html　から参照できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo, data, utils\n",
    "detector = model_zoo.get_model('yolo3_mobilenet1.0_coco', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルはまだメモリに読み込まれた状態ですので、デプロイするためには、このモデルをファイルに保存する必要があります。まず読み込んだモデル `detector` に対して `hybridize()`を実行します。MXNet では、デフォルトではコーディングとデバッグが容易な imperative という形式をとりますが、実行速度やモデルのサイズという観点で最適というわけではありません。そこで、保存のまえに`hybridize()`を実行して、モデルを最適な形に変換します。詳細は[こちら](https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/hybrid.html)をご覧ください。\n",
    "\n",
    "`hybridize()`自体は、効率的なモデルに変換しただけで、そのモデルのリソースはまだ未定なままです。データを入力して初めてリソースが決まり、そのモデルを保存することができます。ここでは、すべて1で次元が(1,3, 320, 320)のテンソルを入力します。\n",
    "\n",
    "あとは、`export`関数によってモデルを保存します。ここでは保存先・ファイル名は以下の通りとします。\n",
    "- model/detector-symbol.json\n",
    "- model/detector-0000.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "detector.hybridize()\n",
    "detector(mx.nd.ones((1,3, 320, 320)))\n",
    "\n",
    "\n",
    "model_dir = \"model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "detector_model = \"detector\"\n",
    "detector.export(\"{}/{}\".format(model_dir, detector_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのアップロード\n",
    "\n",
    "保存が終わったら、SageMaker が読めるように、これを`tar.gz`の形式に圧縮して Amazon S3 にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = 'model.tar.gz'\n",
    "!tar cvzf $archive $model_dir\n",
    "\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "model_uri = sagemaker_session.upload_data(path=archive, key_prefix='detector/model')\n",
    "print('model archive is uploaded to {}'.format(model_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.デプロイ用のコード作成\n",
    "\n",
    "\n",
    "### 必要な実装\n",
    "モデルが作成できたら、次にデプロイ用のコードを書きます。MXNetの場合、デプロイに必要な関数は以下の通りです ([詳細](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#the-sagemaker-mxnet-model-server))\n",
    "\n",
    "- model_fn (required)  \n",
    "デプロイしたモデルを読み込む関数\n",
    "\n",
    "- input_fn/predict_fn/output_fn (option)  \n",
    "推論のリクエストを受け付けたとき、モデルで予測する前のデータ処理を input_fn で行い、predict_fn で予測し、ouput_fn で後処理を行います。実行の流れは以下のようになります。\n",
    "\n",
    "```python\n",
    "# Deserialize the Invoke request body into an object we can perform prediction on\n",
    "input_object = input_fn(request_body, request_content_type)\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "prediction = predict_fn(input_object, model)\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "ouput = output_fn(prediction, response_content_type)\n",
    "```\n",
    "\n",
    "- transform_fn  (option)  \n",
    "input_fn/predict_fn/output_fn を1つの関数で書く場合は transform_fn を使用します。\n",
    "\n",
    "input_fn/predict_fn/output_fn と transform_fn は併用できません。これらの実装が required でない理由として、コンテナ側に標準の実装が行われているからです。例えば、json データの parse は標準的に実装されています。\n",
    "\n",
    "ここでは、`model_fn` と `transform_fn` を実装してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スクリプトの準備\n",
    "\n",
    "ここでは `detector.py` というスクリプトを用意します。まずは以下のコマンドで空のファイルを作成し、以降の作業で実装を行っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch detector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model_fn の実装\n",
    "\n",
    "`model_fn`は、先ほどS3にアップロードしたモデルを読み込む実装となります。S3にモデルをアップロードしていれば、`model_dir` の場所に、ファイルがダウンロード・展開されます。以下のように`gluon.nn.SymbolBlock.imports`を呼び出して実行するコードを`detector.py`に実装しましょう。ファイル名が、保存したファイル名と同じになるようにします。ここでは後で必要なライブラリも import しておきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "import json\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    logging.info(os.listdir(model_dir+\"/model\"))\n",
    "    net = gluon.nn.SymbolBlock.imports(model_dir+ '/model/detector-symbol.json', \n",
    "                                       ['data'], \n",
    "                                       model_dir+ '/model/detector-0000.params')\n",
    "    return net\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform_fn の実装\n",
    "\n",
    "次に `transform_fn` を`detector.py`に実装します。`transform_fn`では、先ほど読み込んだモデルを `net` として受け取ることができます。`data`は推論のリクエストのデータです。\n",
    "\n",
    "\n",
    "```python\n",
    "def transform_fn(net, data, input_content_type, output_content_type):\n",
    "    data = json.loads(data)\n",
    "    nda = mx.nd.array(data)\n",
    "    class_IDs, scores, bounding_boxs = net(nda)\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(class_IDs.shape[0]):\n",
    "        exist_IDs = np.where(class_IDs[i,:,0].asnumpy() >= 0)\n",
    "        output = {\n",
    "            \"class_ids\": class_IDs[i,exist_IDs].asnumpy().tolist(),\n",
    "            \"scores\": scores[i,exist_IDs].asnumpy().tolist(),\n",
    "            \"bbox\": bounding_boxs[i,exist_IDs].asnumpy().tolist()\n",
    "        }\n",
    "        output_list.append(output)\n",
    "\n",
    "    response_body = json.dumps(output_list)\n",
    "    return response_body, output_content_type\n",
    "```\n",
    "\n",
    "\n",
    "まずは`data`に対して前処理を行います。ここでは json 形式でデータを受け取る前提で実装します。そこで `json.loads(data)`で json データを読み込み、Gluonが利用できるようにMXNet の ndrrayの形式に変換します。\n",
    "\n",
    "推論自体は `net(nda)` だけで完了です。推論の結果は、画像に存在するクラスのID, そのスコア、バウンディングボックス (位置）です。\n",
    "\n",
    "これらの情報をそのまま json 形式にして `return` つまり、クライアントにレスポンスとして返してもかまいませんが、少し後処理を加えましょう。 この学習済みのモデルでは、最大100個のオブジェクトを検出することができ、出力として100個のデータを返します。しかし、実際にはもっと少数のオブジェクトが検出されるでしょう。検出されたオブジェクトは正のオブジェクトIDで出力されるので、以下の関数で検出されたオブジェクトのみに絞ります。\n",
    "\n",
    "```\n",
    "exist_IDs = np.where(class_IDs[i,:,0].asnumpy() >= 0)\n",
    "```\n",
    "\n",
    "これらのIDに絞って json 形式とし、return してクライアントに返します。MXNet の ndarray は json に変換できないので、`.asnumpy().tolist()`でリストにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.デプロイ\n",
    "\n",
    "デプロイは、S3にアップロードしたモデルを指定して、`deploy`関数を実行します。MXNetの場合は、`MXNetModel`でモデルの指定を行います。\n",
    "まずコードにエラーがないか確認するために、`local`モードでデプロイします。`local`モードはこのノートブックインスタンスでデプロイすることを意味します。インスタンスの立ち上げが不要なので、待ち時間が発生せず、効率よくデバッグできます。\n",
    "\n",
    "問題がないことを確認できたら、`instance_type` にSagemakerのインスタンスに設定して、APIをたてることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "model = MXNetModel(model_data = model_uri,\n",
    "                       role = get_execution_role(),\n",
    "                       entry_point = \"detector.py\",\n",
    "                        framework_version='1.4',\n",
    "                       py_version='py3')\n",
    "predictor = model.deploy(instance_type=\"local\", initial_instance_count=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに1枚の画像を送ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "im = Image.open('images/dog1.jpg')\n",
    "im = im.resize((320, 320), Image.LANCZOS)\n",
    "data = np.array(im)/255\n",
    "data = np.transpose(data, [2,0,1])\n",
    "data = np.expand_dims(data, axis=0)\n",
    "result = predictor.predict(data.tolist())\n",
    "\n",
    "img =  np.transpose(np.array(im), [2,0,1])\n",
    "ax = utils.viz.plot_bbox(np.array(im),\n",
    "                         labels = np.array(result[0][\"class_ids\"]).reshape(-1),\n",
    "                         scores = np.array(result[0][\"scores\"]).reshape(-1),\n",
    "                         bboxes = np.array(result[0][\"bbox\"][0]),\n",
    "                         class_names=detector.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要になったらエンドポイントを削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.バッチ推論を行う\n",
    "\n",
    "### ファイルのアップロード\n",
    "バッチ変換ジョブを利用することで、Amazon S3にあるファイルを一括で推論することができます。ここでは `images` にある jpg ファイルに対して推論を行います。まず、これらのファイルを S3 にアップロードしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker_session.upload_data(path=\"./images\", key_prefix='detector/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### デプロイのスクリプトの変更\n",
    "\n",
    "バッチ変換ジョブでは、jpg ファイルを直接処理しますので、jpg ファイルの読み込みと前処理を実装する必要があります。ファイルタイプによって処理を分けたい場合は、`input_content_type`ごとに処理を記述します。`detector.py`のtransform_fnを以下の実装に変更しましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def transform_fn(net, data, input_content_type, output_content_type):\n",
    "\n",
    "    from PIL import Image\n",
    "    from six import BytesIO\n",
    "\n",
    "    if input_content_type == \"application/json\":\n",
    "        data = json.loads(data)\n",
    "    elif input_content_type == 'image/jpeg':\n",
    "        im = Image.open(BytesIO(data))\n",
    "        im = im.resize((320, 320), Image.LANCZOS)\n",
    "        data = np.array(im)/255\n",
    "        data = np.transpose(data, [2,0,1])\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    nda = mx.nd.array(data)\n",
    "    class_IDs, scores, bounding_boxs = net(nda)\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(class_IDs.shape[0]):\n",
    "        exist_IDs = np.where(class_IDs[i,:,0].asnumpy() >= 0)\n",
    "        output = {\n",
    "            \"class_ids\": class_IDs[i,exist_IDs].asnumpy().tolist(),\n",
    "            \"scores\": scores[i,exist_IDs].asnumpy().tolist(),\n",
    "            \"bbox\": bounding_boxs[i,exist_IDs].asnumpy().tolist()\n",
    "        }\n",
    "        output_list.append(output)\n",
    "            \n",
    "    response_body = json.dumps(output_list)\n",
    "    return response_body, output_content_type\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチ変換ジョブの実行\n",
    "\n",
    "デプロイの場合と同様にモデルを読み込んでからバッチ変換ジョブを実行します。バッチ変換ジョブは Transformer クラスを定義して実行しますが、その前に create_model でSageMaker モデルを作成しておく必要があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.estimator import MXNet\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "\n",
    "output_path = 's3://' +sagemaker_session.default_bucket() + '/batch_transform/output'\n",
    "\n",
    "model = MXNetModel(model_data = model_uri,\n",
    "                   name =\"gluon-batch-\"+sagemaker_timestamp(),\n",
    "                   role = get_execution_role(),\n",
    "                   sagemaker_session = sagemaker_session,\n",
    "                   entry_point = \"detector.py\",\n",
    "                   framework_version='1.4',\n",
    "                   py_version='py3')\n",
    "\n",
    "container_defs = model.prepare_container_def(instance_type='ml.m4.xlarge')\n",
    "sagemaker_session.create_model(model.name,\n",
    "                              role =  get_execution_role(),\n",
    "                               container_defs = container_defs\n",
    "                              )\n",
    "transformer =Transformer(model_name=model.name,\n",
    "                                instance_count=1,\n",
    "                                output_path=output_path,\n",
    "                                instance_type='ml.m4.xlarge')\n",
    "transformer.transform(image_uri, content_type='image/jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行結果のダウンロード\n",
    "\n",
    "S3 から推論結果をダウンロードしてみてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $output_path ./output --recursive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
