{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker - Bring Your Own Model \n",
    "## MXNet + Gluon 編\n",
    "\n",
    "ここでは [Apache MXNet](https://mxnet.apache.org/) と [Gluon](https://mxnet.incubator.apache.org/versions/master/gluon/index.html) を使ったサンプルコードを題材に、Amazon SageMaker 移行の方法を順を追って説明します。SageMaker Python SDK で MXNet を使うための説明は [SDK のドキュメント](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html) にも多くの情報があります。\n",
    "\n",
    "注: \n",
    "ここで説明するのは Script モード という記法 (現時点では標準の書き方) で、FILE モード (入力データを Amazon S3 から学習時にファイルとしてコピーする方法) です。データサイズが大きくなった場合は、FILE Mode ではなく PIPE Mode をお使い頂いた方がスループットが向上します。\n",
    "また、ここでは以降手順の紹介のためトレーニングスクリプトは最小限の書き換えとしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. トレーニングスクリプトの書き換え\n",
    "まず [サンプルのソースコード](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist/mnist.py) を以下のコマンドでダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/apache/incubator-mxnet/master/example/gluon/mnist/mnist.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードされた `mnist.py` を左のファイルブラウザから見つけて、ダブルクリックで開いて下さい (JupyterLab の場合は左右にファイルを並べると作業しやすいです)。あるいはお好きなエディターをお使い頂いても結構です。\n",
    "\n",
    "書き換える点は主に4点です:\n",
    "1. 環境変数の取得、\n",
    "1. 入力データのディレクトリを変更、\n",
    "1. 学習済みモデルの出力先を変更、\n",
    "1. 推論のためモデルを読み込む。\n",
    "\n",
    "その際に `main` 関数の外で呼んでいる部分 (引数のパース、ニューラルネットワークの定義、データ読み込み) をそれぞれ関数として定義します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 環境変数の取得\n",
    "\n",
    "Amazon SageMaker の Script Mode では、トレーニングに用いるコードが実行時に Python スクリプトとして実行されます。その際、データ・モデルの入出力は [こちら](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#preparing-the-mxnet-training-script) に記述があるよう `SM_CHANNEL_XXXX` や `SM_MODEL_DIR` という環境変数を参照する必要があります。そのため、`argparse.ArgumentParser` で渡された環境変数と、スクリプト実行時のハイパーパラメータを取得します。\n",
    "\n",
    "![データのやりとり](../img/sagemaker-data-model.png)\n",
    "\n",
    "`SM_CHANNEL_TRAIN`, `SM_CHANNEL_TEST`, `SM_MODEL_DIR` を取得するよう以下のように3行書き足します (`parser.parse_args` を呼んでいる [45行目](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist/mnist.py#L45) の前あたりに)。\n",
    "\n",
    "```\n",
    "parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n",
    "parser.add_argument('--sm-model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "```\n",
    "\n",
    "その上で、\n",
    "```\n",
    "parser = argparse.ArgumentParser(description='MXNet Gluon MNIST Example')\n",
    "```\n",
    "から\n",
    "```\n",
    "opt = parser.parse_args()\n",
    "```\n",
    "までの行を、\n",
    "`parse_args` などという関数として定義しましょう (`opt` を返します)。途中省略しますがこんな感じです: \n",
    "\n",
    "```\n",
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='MXNet Gluon MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=100,\n",
    "                        help='batch size for training and testing (default: 100)')\n",
    "    ...\n",
    "    parser.add_argument('--sm-model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    return opt\n",
    "```\n",
    "\n",
    "トレーニングスクリプトは `main` 関数から実行されるので、その冒頭で \n",
    "```\n",
    "opt = parse_args()\n",
    "```\n",
    "を呼び出します。`train` 関数の定義で引数を `epochs` ではなく `opt` に書き換えます (`opt.epochs` だけでなく `opt.train`, `opt.test` も使うため)。代わりに train 関数の先頭で\n",
    "```\n",
    "epochs = opt.epochs\n",
    "```\n",
    "と追記しておきましょう。\n",
    "また、`main` の中で `train(opt, ctx)` と呼ぶようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 入力データのディレクトリを変更\n",
    "\n",
    "元のコードでは `gluon.data.DataLoader` を使ってデータのダウンロード・読み込みを行なっています。Amazon SageMaker では先ほど環境変数から取得した `opt.train`, `opt.test` (変数の値は、以下で指定するようにそれぞれ `/opt/ml/input/data/train`, `/opt/ml/input/data/test` となる予定。詳細は [ドキュメント](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html#your-algorithms-training-algo-running-container-trainingdata) をご覧下さい) にデータを読みにいくよう書き換える必要があります。FILE Mode の場合、トレーニングコンテナ起動時に S3 からこれらのディレクトリへデータがコピーされます。\n",
    "\n",
    "`gluon.data.DataLoader` を使ってデータを読んでいる2箇所の\n",
    "```\n",
    "gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST('./data', ...)\n",
    "```\n",
    "を、以下のように書き換えます。\n",
    "```\n",
    "gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(opt.train, ...)\n",
    "gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(opt.test, ...)\n",
    "```\n",
    "\n",
    "元々のコードの場合は、この場所で `gluon.data.vision.MNIST` を使ってインターネットからデータをダウンロードしていました。`gluon.data.vision.MNIST` は指定されたディレクトリにデータを探しに行き、そこにファイルが置かれている場合は別途ダウンロードせずにファイルを直接読み込みむので、この第一引数 `root` を書き換えてあげれば期待通り Amazon S3 からのデータを読んでくれます。\n",
    "\n",
    "ここも、`load_data` のような関数として定義しましょう (`opt` を引数に取って `train_data, val_data` を返します)。こんな感じです:\n",
    "\n",
    "```\n",
    "def load_data(opt):\n",
    "    train_data = gluon.data.DataLoader(\n",
    "        gluon.data.vision.MNIST(opt.train, train=True, transform=transformer),\n",
    "        batch_size=opt.batch_size, shuffle=True, last_batch='discard')\n",
    "\n",
    "    val_data = gluon.data.DataLoader(\n",
    "        gluon.data.vision.MNIST(opt.test, train=False, transform=transformer),\n",
    "        batch_size=opt.batch_size, shuffle=False)\n",
    "    \n",
    "    return train_data, val_data\n",
    "```\n",
    "\n",
    "`train` 関数の中で以下のように呼び出します。\n",
    "```\n",
    "train_data, val_data = load_data(opt)\n",
    "```\n",
    "また `test` 関数に `net`, `val_data` を渡すようにします (グローバル変数でなくなったので引数で渡す必要があります)。元のコードの [72行目](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist/mnist.py#L72) と [117行目](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist/mnist.py#L117) です。\n",
    "\n",
    "後ほど、Notebook 上で予めデータをダウンロードしておいて、Amazon S3 にアップロードする作業を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 学習済みモデルの出力先を変更\n",
    "\n",
    "モデルは `net.save_parameters('mnist.params')` で保存されています。Amazon SageMaker では、指定されたディレクトリ `opt.sm_model_dir` (すなわち `/opt/ml/model`) に学習結果を保存すると、Amazon S3 へアップロードしてくれます。\n",
    "\n",
    "以下のように書き換えるやり方でも重みを保存できますが、\n",
    "> \n",
    "> ```net.save_parameters(os.path.join(opt.sm_model_dir, 'mnist.params'))```\n",
    "> \n",
    "> ここで、`os.path.join` を呼んでいるので忘れずに `import os` も書いておきましょう。\n",
    "> \n",
    "> ニューラルネットワークの定義を `net` を返す関数にします。例えば `define_network` という関数名だとすると、`train` 関数の冒頭で `net = define_network()` を呼びます。\n",
    "\n",
    "ここでは Gluon の [`mxnet.gluon.HybridBlock.export`](https://mxnet.incubator.apache.org/api/python/gluon/gluon.html#mxnet.gluon.HybridBlock.export) を使ってモデルと重みを保存することにします。まず、モデルの定義で `HybridSequential` を使うように\n",
    "```\n",
    "net = nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(128, activation='relu'))\n",
    "    net.add(nn.Dense(64, activation='relu'))\n",
    "    net.add(nn.Dense(10))\n",
    "net.hybridize()\n",
    "```\n",
    "と書き換えます。最後の行で `hybridize` を呼ぶことを忘れないでください。これはモデルのシリアライズのために必要で、パフォーマンスの向上にも寄与します。\n",
    "\n",
    "`net.save_parameters` を以下に書き換えて、\n",
    "```\n",
    "net.export(os.path.join(opt.sm_model_dir, 'mlp'))\n",
    "```\n",
    "冒頭 [20行目](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist/mnist.py#L20) あたり に `import os` も書き足します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 推論のためモデルを読み込む\n",
    "\n",
    "ここまでの変更で Amazon SageMaker 上のトレーニングが実行できるようになりましたが、モデルのホスティングのため、`model_fn` を定義する必要があります。この関数は `model_dir` を引数にとり、ニューラルネットワーク `net` (ここでは `mxnet.gluon.nn.Sequential`) のモデル (`mlp-symbol.json`) と重み (`mlp-0000.params`) を読み込み `net` を返します。\n",
    "\n",
    "```\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the gluon model. Called once when hosting service starts.\n",
    "\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a model (in this case a Gluon network)\n",
    "    \"\"\"\n",
    "    \n",
    "    net = gluon.nn.SymbolBlock.imports('mlp-symbol.json', ['data'], 'mlp-0000.params')\n",
    "    \n",
    "    return net\n",
    "```\n",
    "\n",
    "前処理・後処理などの詳細は [API ドキュメント](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#the-sagemaker-mxnet-model-server) に記載があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notebook 上でのデータ準備\n",
    "\n",
    "トレーニングスクリプトの書き換えは終了しました。トレーニングを始める前に、予め Amazon S3 にデータを準備しておく必要があります。この Notebook を使ってその作業をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほど書き換えたトレーニングスクリプトの中には、`transformer` という関数が定義され前処理のデータ変換 (正規化) が含まれていました。それも含め、`gluon.data.vision.MNIST` でダウンロード・データ変換を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(data, label):\n",
    "    data = data.reshape((-1,)).astype(np.float32)/255\n",
    "    return data, label\n",
    "\n",
    "train = gluon.data.vision.MNIST('./data/train', train=True, transform=transformer)\n",
    "test = gluon.data.vision.MNIST('./data/test', train=False, transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを Amazon S3 にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker_session.upload_data(path='data/train', key_prefix='data/handson-byom-mxnet-mnist/train')\n",
    "test_data = sagemaker_session.upload_data(path='data/test', key_prefix='data/handson-byom-mxnet-mnist/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local Mode によるトレーニングとコードの検証\n",
    "トレーニングジョブを始める前に、Local Mode を使って、この Notebook インスタンス上でコンテナを立てコードをデバッグしましょう。\n",
    "\n",
    "`from sagemaker.mxnet import MXNet` で読み込んだ SageMaker Python SDK の MXNet Estimator を作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = \"local\"\n",
    "\n",
    "estimator = MXNet(\"mnist.py\",\n",
    "                  role=role,\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type=train_instance_type,\n",
    "                  py_version='py3', \n",
    "                  framework_version=\"1.4.0\",\n",
    "                  hyperparameters={'batch-size': 100,\n",
    "                                   'epochs': 4,\n",
    "                                   'lr': 0.1,\n",
    "                                   'momentum': 0.9, \n",
    "                                   'log-interval': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`estimator.fit` によりトレーニングを開始しますが、ここで指定する「チャネル」によって、環境変数名 `SM_CHANNEL_XXXX` が決定されます。この例の場合、`'train', 'test'` を指定しているので、`SM_CHANNEL_TRAIN`, `SM_CHANNEL_TEST` となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mnist.py` の中で書き換えを忘れた部分があったら、ここでエラーとなる場合があります。Local Mode ではクイックにデバッグができるので、正しく実行できるよう試行錯誤しましょう。\n",
    "\n",
    " `===== Job Complete =====`\n",
    "と表示されれば成功です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの確認\n",
    "\n",
    "Amazon S3 に保存されたモデルは普通にダウンロードしてきて使うこともできます。保存先は `estimator.model_data` で確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS CLI を使ってノートブックインスタンス上に持ってきて、試しに推論させてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $estimator.model_data ./\n",
    "!tar -zxvf model.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "net = gluon.nn.SymbolBlock.imports('mlp-symbol.json', ['data'], 'mlp-0000.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = gluon.data.DataLoader(test, batch_size=10)\n",
    "\n",
    "for data, label in test_dataloader:\n",
    "    print('label:', label.asnumpy())\n",
    "    pred = net(data)\n",
    "    print('pred: ', pred.asnumpy().argmax(axis=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. トレーニングジョブの発行\n",
    "\n",
    "正しく推論されていればコードのデバッグは完了です。次に、Amazon SageMaker のトレーニングジョブとしてトレーニングをさせます。データ・モデルの入出力は変わらず S3 なので、`train_instance_type` に `ml.` で始まる SageMaker のインスタンスを指定するだけで実行できます。(リストは[こちら](https://aws.amazon.com/sagemaker/pricing/instance-types/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "# train_instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "estimator = MXNet(\"mnist.py\",\n",
    "                  role=role,\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type=train_instance_type,\n",
    "                  py_version='py3', \n",
    "                  framework_version=\"1.4.0\",\n",
    "                  hyperparameters={'batch-size': 100,\n",
    "                                   'epochs': 20,\n",
    "                                   'lr': 0.1,\n",
    "                                   'momentum': 0.9, \n",
    "                                   'log-interval': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "```\n",
    "Billable seconds: <time>\n",
    "```\n",
    "と出力されればトレーニング終了です。これが実際にトレーニングインスタンスが課金される時間となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 推論エンドポイントのデプロイ\n",
    "\n",
    "`estimator.deploy` で、今トレーニングしたモデルを推論エンドポイントとしてデプロイすることができます。これには数分かかります。(`----!` と表示されればデプロイ完了です。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = gluon.data.DataLoader(test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in test_dataloader:\n",
    "    print('label:', label.asnumpy())\n",
    "    pred = predictor.predict(data.asnumpy())\n",
    "    print('pred: ', np.array(pred).argmax(axis=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論エンドポイントは立てっぱなしにしているとお金がかかるので、確認が終わったら忘れないうちに削除してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache MXNet と Gluon を使った Amazon SageMaker への移行手順について紹介しました。普段お使いのモデルでも同様の手順で移行が可能ですのでぜひ試してみてください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
