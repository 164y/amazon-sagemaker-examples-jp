{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker を使った学習済 Keras モデルのデプロイ\n",
    "このノートブックは、[SageMaker TensorFlow Serving コンテナ](https://github.com/aws/sagemaker-tensorflow-serving-container) でリアルタイム推論を実行する方法を示します。 TensorFlow Servingコンテナは、スクリプトモードのデフォルトの推論方法です。より詳細なドキュメントについては、[こちら](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst)にアクセスしてください。\n",
    "\n",
    "Amazon SageMaker python SDK でモデルをデプロイするためには、Estimator クラスの deploy（）メソッドを使って SageMaker モデルを作成します。このモデルはエンドポイントにデプロイされ、リアルタイムで予測リクエストを処理します。 スクリプトモードでトレーニングしたため、エンドポイントには TensorFlow Serving コンテナを使用します。 このサービングコンテナは、SageMaker ホスティングプロトコルと互換性のあるWebサーバーの実装を実行します。 独自の推論コードの使用 ドキュメントでは、SageMaker が推論コンテナを実行する方法について説明しています。\n",
    "\n",
    "Keras/TensorFlow モデルをデプロイするためには、 TensorFlow SavedModel 形式でモデルを保存する必要があります。\n",
    "本ハンズオンでは学習スクリプトの中で既に`def save_model(model, output):`として実装されています。\n",
    "\n",
    "\n",
    "入力データと出力データの形式は、[TensorFlow Serving REST API](https://www.tensorflow.org/tfx/serving/api_rest) の Predictメソッドのリクエストとレスポンスの形式に直接対応しています。 SageMaker の TensforFlow Serving エンドポイントは、単純化されたJSON形式、行区切りのJSONオブジェクト (\"jsons\" または \"jsonlines\")、CSV データなど、TensorFlow REST API の一部ではない追加の入力形式も受け入れることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済モデルのデプロイ\n",
    "新しくモデルを学習する変わりに、これまでに学習されたモデルを活用しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm_sample1_CloudWatch.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 5},\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.p2.xlarge')\n",
    "\n",
    "\n",
    "estimator = estimator.attach(training_job_name='cifar10-2019-09-30-13-35-29-611')  ## Configure with your previous cifar10 job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論の実行\n",
    "エンドポイントが想定通りに動作するか、ランダムデータを用いて推論してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print(\"Predicted class is {}\".format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデートを用いたモデル精度の測定\n",
    "\n",
    "テストデータセットを用いて混合行列を作成し、モデルの精度を測ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "for data in datagen.flow(x_test,y_test,batch_size=batch_size):\n",
    "    for i,prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted,y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted,y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(cm, annot=True,annot_kws={\"size\": 10})# font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ヒートマップを使うことで、それぞれのラベル毎の正解率を計算することが出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントを削除する\n",
    "余分なコストが発生しないように、検証が終わったら上記で作成したエンドポイントを削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
