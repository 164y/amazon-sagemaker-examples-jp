{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horovod を使った分散学習\n",
    "Horovod は MPI を使った分散学習のためのフレームワークです。より詳細な情報は [Horovod README](https://github.com/uber/horovod) をご確認下さい。\n",
    "\n",
    "Amazon SageMaker では Horovod の活用もスクリプトを少し変更するだけで可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horovod による分散学習を行う学習スクリプトの作成\n",
    "\n",
    "#### **オリジナルの学習スクリプトである`training_script/cifar10_keras_sm.py`をコピーした上で、`training_script/cifar10_keras_dist.py.`として保存して下さい。新しいファイルを書き換え用のファイルとして使います。**\n",
    "\n",
    "\n",
    "#### ① Horovod の初期設定\n",
    "\n",
    "Horovod を使用するように `main()` 関数の中に 下記を追加します。\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    import horovod.keras as hvd\n",
    "    hvd.init()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "    K.set_session(tf.Session(config=config))\n",
    "```\n",
    "\n",
    "#### ② Callbacks の設定\n",
    "\n",
    "Horovod へ対応するために `main()` 関数の中に callbacks を追加します。\n",
    "\n",
    "```python\n",
    "    callbacks.append(hvd.callbacks.BroadcastGlobalVariablesCallback(0))\n",
    "    callbacks.append(hvd.callbacks.MetricAverageCallback())\n",
    "    callbacks.append(hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, verbose=1))\n",
    "```\n",
    "\n",
    "また、checkpoint と tensorboard の callback がシングルプロセスのログだけ送信するように変更します。 \n",
    "\n",
    "```python\n",
    "    if hvd.rank() == 0:\n",
    "        callbacks.append(ModelCheckpoint(args.model_output_dir + '/checkpoint-{epoch}.h5'))\n",
    "        callbacks.append(TensorBoard(log_dir=args.model_output_dir,update_freq='epoch'))\n",
    "```\n",
    "\n",
    "#### ③ Horovod に対応した Optimizer の設定変更\n",
    "Horovod へ対応するために keras_model_fn へ `hvd` 引数を追加します。\n",
    "\n",
    "```python\n",
    "#  hvd を追加します。\n",
    "def keras_model_fn(learning_rate, weight_decay, optimizer, momentum, hvd): \n",
    "```\n",
    "\n",
    "その、`keras_model_fn()` 関数の中において`size=1` を `size=hvd.size()`　へ変更。\n",
    "さらに、\n",
    "```python\n",
    " model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "```\n",
    "の直前に\n",
    "\n",
    "```python\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "を追加します。\n",
    "\n",
    "\n",
    "最後に、`main()` 関数の中で、model インスタンスを作成する際に、`hvd` を引数に渡すよう書き換えます。\n",
    "```python\n",
    "model = keras_model_fn(args.learning_rate, args.weight_decay, args.optimizer, args.momentum, hvd)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分散学習の実行\n",
    "下記の設定を Estimator オブジェクトに渡すことで Horovod で分散学習についての設定をすることができます。\n",
    "\n",
    "```python\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': # それぞれのホストでのインスタンスの数\n",
    "                        }\n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10')\n",
    "# display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は各ホストで1プロセスが実行されるような設定としています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': 1}\n",
    "                }\n",
    "\n",
    "# Change base_job_name to 'cifar10-dist' for console visibility\n",
    "estimator = TensorFlow(base_job_name='cifar10-dist',\n",
    "                       entry_point='cifar10_keras_dist.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 10},\n",
    "                       train_instance_count=2,\n",
    "                       train_instance_type='ml.p2.xlarge',\n",
    "                       distributions=distributions\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
