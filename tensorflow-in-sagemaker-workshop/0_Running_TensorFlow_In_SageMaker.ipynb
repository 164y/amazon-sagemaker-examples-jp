{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker を使った Keras Sequential モデルの学習\n",
    "ここでは Keras を使ったサンプルコードを題材に、Amazon SageMaker への移行方法を順を追って説明します。このノートブックで用いるモデルは [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py) でも紹介さている CNN モデルになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット\n",
    "本ハンズオンでは [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) という機械学習では最も有名なデータセットの一つを使います。32✕32ピクセル、10個の異なるクラスからなる60,000枚の画像を分類します。下記にランダムに選んできた画像をご紹介します。\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "cifar10 の tfrecord 形式のデータセットを `s3://floor28/data/cifar10` からノートブックインスタンス上へ AWS CLI コマンドを使ってダウンロードしてきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://floor28/data/cifar10 ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 書き換え前の学習スクリプトをノートブックインスタンス上で実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習スクリプトは設定のために下記の引数が必要です。\n",
    "\n",
    "1. model_dir : ログやチェックポイントを保存するためのパス\n",
    "2. train, validation, eval : それぞれのtfrecordデータを保存するためのパス\n",
    "\n",
    "学習スクリプトをノートブックインスタンスの環境で実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p logs\n",
    "!python training_script/cifar10_keras.py --model_dir ./logs \\\n",
    "                                         --train data/train \\\n",
    "                                         --validation data/validation \\\n",
    "                                         --eval data/eval \\\n",
    "                                         --epochs 1\n",
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow スクリプトモードでの学習\n",
    "TensorFlow versions 1.11 以降では, Amazon SageMaker Python SDK ではスクリプトモードをサポートします。SageMaker で TensorFlow トレーニングスクリプトを最小限の変更で実行できます。SageMaker Python SDK は、 SageMaker トレーニングインスタンスへのスクリプトの転送を処理します。トレーニングインスタンスでは、SageMaker のネイティブ TensorFlow サポートがトレーニング関連の環境変数を設定し、トレーニングスクリプトを実行します。\n",
    "\n",
    "スクリプトモードは Python 2.7- と Python 3.6- の両方でお使い頂けます。また、Horovod による分散学習にも対応してます。詳細は[コチラ](https://sagemaker.readthedocs.io/en/stable/using_tf.html)をご確認下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習スクリプトを SageMaker 向けに書き換える\n",
    "SageMaker の学習インスタンスでは学習用のコンテナへ Amazon S3 に保存されたデータをダウンロードし学習へ活用します。その際、S3 バケットのデータのパスとコンテナ内のデータのパスを、コンテナの環境変数を介して関連付けます。また、学習によって作成された学習済モデルやそのチェックポイントなどの生成物も同様に環境変数と関連付けられます。\n",
    "\n",
    "今回の cifer10 のデータセットでは Train、Validation、Eval の3種類のデータがあるため下記のように紐付けます。\n",
    "\n",
    "\n",
    "|  S3 location  |  環境変数  |  値  |\n",
    "| :---- | :---- | :----| \n",
    "|  s3://bucket_name/prefix/train  |  `SM_CHANNEL_TRAIN`  | `/opt/ml/input/data/train`  |\n",
    "|  s3://bucket_name/prefix/validation  |  `SM_CHANNEL_VALIDATION`  | `/opt/ml/input/data/validation`  |\n",
    "|  s3://bucket_name/prefix/eval  |  `SM_CHANNEL_EVAL`  | `/opt/ml/input/data/eval`  |\n",
    "|  s3://bucket_name/prefix/model.tar.gz  |  `SM_MODEL_DIR`  |  `/opt/ml/model`  |\n",
    "|  s3://bucket_name/prefix/output.tar.gz  |  `SM_OUTPUT_DATA_DIR`  |  `/opt/ml/output/data`  |\n",
    "\n",
    "詳細は SageMaker Python SDK の[ドキュメント](https://sagemaker.readthedocs.io/en/stable/using_tf.html#preparing-a-script-mode-training-script)をご確認下さい。また [Amazon SageMaker で簡単に Keras を使う方法](https://aws.amazon.com/jp/blogs/news/amazon-sagemaker-keras/)というブログ記事もご参考に下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **オリジナルの学習スクリプトである`training_script/cifar10_keras.py`をコピーした上で、`training_script/cifar10_keras_sm.py.`として保存して下さい。新しいファイルを書き換え用のファイルとして使います。**\n",
    "\n",
    "このサンプルコードではネットワーク遅延をへらすために、モデルのチェックポイントをローカル環境へ保存します。これらは学習ジョブが終了した際に s3 へアップロードすることができます。\n",
    "\n",
    "**①下記を `cifar10_keras_sm.py` の`if __name__ == ‘__main__’:` ブロックの中へ追加して下さい。**\n",
    "\n",
    "```python\n",
    "parser.add_argument(\n",
    "        '--model_output_dir',\n",
    "        type=str,\n",
    "        default=os.environ.get('SM_MODEL_DIR'))\n",
    "```\n",
    "\n",
    "\n",
    "**② `if __name__ == ‘__main__’:`中のチャンネル引数の部分に `default=os.environ['SM_CHANNEL_XXXX']` を追加して下さい。**\n",
    "\n",
    "```python\n",
    "parser.add_argument(\n",
    "    '--train',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_TRAIN'],  # 追加項目\n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "    \n",
    "parser.add_argument(\n",
    "    '--validation',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_VALIDATION'],　# 追加項目\n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "    \n",
    "parser.add_argument(\n",
    "    '--eval',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_EVAL'],　# 追加項目\n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "```\n",
    "\n",
    "**③`ModelCheckPoint` ラインを新しい保存先を使うよう変更します。**\n",
    "```python\n",
    "callbacks.append(ModelCheckpoint(args.model_output_dir + '/checkpoint-{epoch}.h5'))\n",
    "```\n",
    "\n",
    "**④`save_model()` 関数の呼び出し部分を新しい保存先を呼び出すように変更します。**\n",
    "  ```python\n",
    "return save_model(model, args.model_dir)\n",
    "```\n",
    "から、\n",
    "```python\n",
    "return save_model(model, args.model_output_dir)\n",
    "```\n",
    "へ変更します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker ローカルモードを使った学習スクリプト書き換えの検証\n",
    "トレーニングジョブを始める前に、ローカルモードを使って、このノートブックインスタンス上でコンテナを立てコードをデバッグしましょう。ローカルモードでは、Docker compose と NVIDIA Docker を使い、Amazon ECS から Amazon SageMaker TensorFlow コンテナをダウンロードしてきて使います。これにより、SageMaker Python SDK は CPU (single and multi-instance) や GPU (single instance) をエミュレートした環境をノートブックインスタンス上に構築します。\n",
    "\n",
    "ローカルモードを使うことによって、コードの素早い検証を行ったり、既にお持ちの学習環境があればそのハードウェア資産を有効活用したりすることなどが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from sagemaker.tensorflow import TensorFlow` で読み込んだ SageMaker Python SDK の TensorFlow Estimator を作ります。詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#training-with-tensorflow-estimator)をご確認下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 5},\n",
    "                       train_instance_count=1, train_instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使うデータセットに合わせて3つのチャネルとそのデータのパスを指定します。今回はローカルモードなので、ノートブックインスタンス上のパスを指定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train' :  'file://data/train',\n",
    "               'validation' :  'file://data/validation',\n",
    "               'eval' :  'file://data/eval'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SageMaker for faster training time\n",
    "SageMakerでの学習にGPUインスタンスを使うことで学習時間を速めることが出来ます。学習を始める前に、予め Amazon S3 にデータを準備しておく必要があります。このノートブックを使ってその作業をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は **ml.p2.xlarge** インスタンスを使用し、エポック数を **epochs:5** と指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 5},\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ジョブを発行します。今回はそれぞれのチャネルに S3 のデータ保存先を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Billable seconds: <time>\n",
    "```\n",
    "\n",
    "と出力されればトレーニング終了です。これが実際にトレーニングインスタンスが課金される時間となります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
