{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker を使った Keras Sequential モデルの学習\n",
    "ここでは Keras を使ったサンプルコードを題材に、Amazon SageMaker への移行方法を順を追って説明します。このノートブックで用いるモデルは [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py) でも紹介さている CNN モデルになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット\n",
    "本ハンズオンでは [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) という機械学習では最も有名なデータセットの一つを使います。32✕32ピクセル、10個の異なるクラスからなる60,000枚の画像を分類します。下記にランダムに選んできた画像をご紹介します。\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "cifar10 の tfrecord 形式のデータセットを `s3://floor28/data/cifar10` からノートブックインスタンス上へ AWS CLI コマンドを使ってダウンロードしてきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://floor28/data/cifar10/eval/eval.tfrecords to data/eval/eval.tfrecords\n",
      "download: s3://floor28/data/cifar10/validation/validation.tfrecords to data/validation/validation.tfrecords\n",
      "download: s3://floor28/data/cifar10/train/train.tfrecords to data/train/train.tfrecords\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://floor28/data/cifar10 ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ローカルで書き換え前の学習スクリプトの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習スクリプトは設定のために下記の引数が必要です。\n",
    "\n",
    "1. model_dir : ログやチェックポイントを保存するためのパス\n",
    "2. train, validation, eval : それぞれのtfrecordデータを保存するためのパス\n",
    "\n",
    "学習スクリプトをノートブックインスタンスの環境で実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p logs\n",
    "!python training_script/cifar10_keras.py --model_dir ./logs \\\n",
    "                                         --train data/train \\\n",
    "                                         --validation data/validation \\\n",
    "                                         --eval data/eval \\\n",
    "                                         --epochs 1\n",
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow スクリプトモードでの学習\n",
    "TensorFlow versions 1.11 以降では, Amazon SageMaker Python SDK ではスクリプトモードをサポートします。SageMaker で TensorFlow トレーニングスクリプトを最小限の変更で実行できます。SageMaker Python SDK は、 SageMaker トレーニングインスタンスへのスクリプトの転送を処理します。トレーニングインスタンスでは、SageMaker のネイティブ TensorFlow サポートがトレーニング関連の環境変数を設定し、トレーニングスクリプトを実行します。\n",
    "\n",
    "スクリプトモードは Python 2.7- と Python 3.6- の両方でお使い頂けます。また、Horovod による分散学習にも対応してます。詳細は[コチラ](https://sagemaker.readthedocs.io/en/stable/using_tf.html)をご確認下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習スクリプトを SageMaker 向けに書き換える\n",
    "SageMaker の学習インスタンスでは学習用のコンテナへ Amazon S3 に保存されたデータをダウンロードし学習へ活用します。その際、S3 バケットのデータのパスとコンテナ内のデータのパスを、コンテナの環境変数を介して関連付けます。また、学習によって作成された学習済モデルやそのチェックポイントなどの生成物も同様に環境変数と関連付けられます。\n",
    "\n",
    "今回の cifer10 のデータセットでは Train、Validation、Eval の3種類のデータがあるため下記のように紐付けます。\n",
    "\n",
    "\n",
    "|  S3 location  |  環境変数  |  値  |\n",
    "| :---- | :---- | :----| \n",
    "|  s3://bucket_name/prefix/train  |  `SM_CHANNEL_TRAIN`  | `/opt/ml/input/data/train`  |\n",
    "|  s3://bucket_name/prefix/validation  |  `SM_CHANNEL_VALIDATION`  | `/opt/ml/input/data/validation`  |\n",
    "|  s3://bucket_name/prefix/eval  |  `SM_CHANNEL_EVAL`  | `/opt/ml/input/data/eval`  |\n",
    "|  s3://bucket_name/prefix/model.tar.gz  |  `SM_MODEL_DIR`  |  `/opt/ml/model`  |\n",
    "|  s3://bucket_name/prefix/output.tar.gz  |  `SM_OUTPUT_DATA_DIR`  |  `/opt/ml/output/data`  |\n",
    "\n",
    "詳細は SageMaker Python SDK の[ドキュメント](https://sagemaker.readthedocs.io/en/stable/using_tf.html#preparing-a-script-mode-training-script)をご確認下さい。また [Amazon SageMaker で簡単に Keras を使う方法](https://aws.amazon.com/jp/blogs/news/amazon-sagemaker-keras/)というブログ記事もご参考に下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **オリジナルの学習スクリプトである`training_script/cifar10_keras.py`をコピーした上で、`training_script/cifar10_keras_sm.py.`として保存して下さい。新しいファイルを書き換え用のファイルとして使います。**\n",
    "\n",
    "このサンプルコードではネットワーク遅延をへらすために、モデルのチェックポイントをローカル環境へ保存します。これらは学習ジョブが終了した際に s3 へアップロードすることができます。\n",
    "\n",
    "**①下記を `cifar10_keras_sm.py` の`if __name__ == ‘__main__’:` ブロックの中へ追加して下さい。**\n",
    "\n",
    "```python\n",
    "parser.add_argument(\n",
    "        '--model_output_dir',\n",
    "        type=str,\n",
    "        default=os.environ.get('SM_MODEL_DIR'))\n",
    "```\n",
    "\n",
    "\n",
    "**② `default=os.environ['SM_CHANNEL_XXXX']` を train、validation、eval のそれぞれに追加して下さい。**\n",
    "\n",
    "```python\n",
    "parser.add_argument(\n",
    "    '--train',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_TRAIN'], \n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "    \n",
    "parser.add_argument(\n",
    "    '--validation',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_VALIDATION'],\n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "    \n",
    "parser.add_argument(\n",
    "    '--eval',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    default=os.environ['SM_CHANNEL_EVAL'],\n",
    "    help='The directory where the CIFAR-10 input data is stored.')\n",
    "```\n",
    "\n",
    "**③`ModelCheckPoint` ラインを新しい保存先を使うよう変更します。**\n",
    "```python\n",
    "callbacks.append(ModelCheckpoint(args.model_output_dir + '/checkpoint-{epoch}.h5'))\n",
    "```\n",
    "\n",
    "**④`save_model call` を新しい保存先を呼び出すように変更します。**\n",
    "  ```python\n",
    "return save_model(model, args.model_dir)\n",
    "```\n",
    "から、\n",
    "```python\n",
    "return save_model(model, args.model_output_dir)\n",
    "```\n",
    "へ変更します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker ローカルモードを使った学習スクリプト書き換えの検証\n",
    "トレーニングジョブを始める前に、ローカルモードを使って、このノートブックインスタンス上でコンテナを立てコードをデバッグしましょう。ローカルモードでは、Docker compose と NVIDIA Docker を使い、Amazon ECS から Amazon SageMaker TensorFlow コンテナをダウンロードしてきて使います。これにより、SageMaker Python SDK は CPU (single and multi-instance) や GPU (single instance) をエミュレートした環境をノートブックインスタンス上に構築します。\n",
    "\n",
    "ローカルモードを使うことによって、コードの素早い検証を行ったり、既にお持ちの学習環境があればそのハードウェア資産を有効活用したりすることなどが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from sagemaker.tensorflow import TensorFlow` で読み込んだ SageMaker Python SDK の TensorFlow Estimator を作ります。詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/using_tf.html#training-with-tensorflow-estimator)をご確認下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 20},\n",
    "                       train_instance_count=1, train_instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使うデータセットに合わせて3つのチャネルとそのデータのパスを指定します。今回はローカルモードなので、ノートブックインスタンス上のパスを指定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train' :  'file://data/train',\n",
    "               'validation' :  'file://data/validation',\n",
    "               'eval' :  'file://data/eval'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SageMaker for faster training time\n",
    "SageMakerでの学習にGPUインスタンスを使うことで学習時間を速めることが出来ます。学習を始める前に、予め Amazon S3 にデータを準備しておく必要があります。このノートブックを使ってその作業をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-815969174475/data/DEMO-cifar10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は **ml.p3.2xlarge** インスタンスを使用し、エポック数を **epochs:20** と指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm_sample0.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 1},\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ジョブを発行します。今回はそれぞれのチャネルに S3 のデータ保存先を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01 02:24:34 Starting - Starting the training job...\n",
      "2019-10-01 02:24:35 Starting - Launching requested ML instances......\n",
      "2019-10-01 02:25:36 Starting - Preparing the instances for training......\n",
      "2019-10-01 02:26:53 Downloading - Downloading input data...\n",
      "2019-10-01 02:27:21 Training - Downloading the training image...\n",
      "2019-10-01 02:27:45 Training - Training image download completed. Training in progress.\u001b[31m2019-10-01 02:27:48,940 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[31m2019-10-01 02:27:49,421 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-2019-10-01-02-24-33-462\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_keras_sm_sample0\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_keras_sm_sample0.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=cifar10_keras_sm_sample0.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=cifar10_keras_sm_sample0\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-2019-10-01-02-24-33-462\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_sm_sample0\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_keras_sm_sample0.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python cifar10_keras_sm_sample0.py --epochs 1 --model_dir s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mNamespace(batch_size=128, epochs=1, eval='/opt/ml/input/data/eval', learning_rate=0.001, model_dir='s3://sagemaker-us-east-1-815969174475/cifar10-2019-10-01-02-24-33-462/model', model_output_dir='/opt/ml/model', momentum=0.9, optimizer='adam', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation', weight_decay=0.0002)\u001b[0m\n",
      "\u001b[31mINFO:root:getting data\u001b[0m\n",
      "\u001b[31mINFO:root:configuring model\u001b[0m\n",
      "\u001b[31mINFO:root:Starting training\u001b[0m\n",
      "\u001b[31mTrain on 128 samples, validate on 128 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/1\u001b[0m\n",
      "\u001b[31m  1/312 [..............................] - ETA: 37:51 - loss: 3.8364 - acc: 0.1016\n",
      "  2/312 [..............................] - ETA: 19:01 - loss: 3.6780 - acc: 0.1016\u001b[0m\n",
      "\u001b[31m  3/312 [..............................] - ETA: 12:44 - loss: 3.6316 - acc: 0.1068\n",
      "  4/312 [..............................] - ETA: 9:36 - loss: 3.6159 - acc: 0.1152 \n",
      "  5/312 [..............................] - ETA: 7:43 - loss: 3.5689 - acc: 0.1172\n",
      "  6/312 [..............................] - ETA: 6:28 - loss: 3.5089 - acc: 0.1146\n",
      "  7/312 [..............................] - ETA: 5:34 - loss: 3.4336 - acc: 0.1150\n",
      "  8/312 [..............................] - ETA: 4:53 - loss: 3.3970 - acc: 0.1133\n",
      "  9/312 [..............................] - ETA: 4:22 - loss: 3.3522 - acc: 0.1163\n",
      " 10/312 [..............................] - ETA: 3:57 - loss: 3.2959 - acc: 0.1211\n",
      " 11/312 [>.............................] - ETA: 3:36 - loss: 3.2322 - acc: 0.1214\n",
      " 12/312 [>.............................] - ETA: 3:19 - loss: 3.1756 - acc: 0.1276\n",
      " 13/312 [>.............................] - ETA: 3:04 - loss: 3.1417 - acc: 0.1256\n",
      " 14/312 [>.............................] - ETA: 2:52 - loss: 3.0951 - acc: 0.1295\n",
      " 15/312 [>.............................] - ETA: 2:41 - loss: 3.0554 - acc: 0.1323\n",
      " 16/312 [>.............................] - ETA: 2:32 - loss: 3.0213 - acc: 0.1323\n",
      " 17/312 [>.............................] - ETA: 2:23 - loss: 2.9836 - acc: 0.1356\n",
      " 18/312 [>.............................] - ETA: 2:16 - loss: 2.9459 - acc: 0.1406\n",
      " 19/312 [>.............................] - ETA: 2:09 - loss: 2.9122 - acc: 0.1431\u001b[0m\n",
      "\u001b[31m 20/312 [>.............................] - ETA: 2:03 - loss: 2.8826 - acc: 0.1445\n",
      " 21/312 [=>............................] - ETA: 1:58 - loss: 2.8626 - acc: 0.1440\n",
      " 22/312 [=>............................] - ETA: 1:53 - loss: 2.8373 - acc: 0.1449\n",
      " 23/312 [=>............................] - ETA: 1:48 - loss: 2.8113 - acc: 0.1464\n",
      " 24/312 [=>............................] - ETA: 1:44 - loss: 2.7868 - acc: 0.1471\n",
      " 25/312 [=>............................] - ETA: 1:40 - loss: 2.7659 - acc: 0.1478\n",
      " 26/312 [=>............................] - ETA: 1:37 - loss: 2.7419 - acc: 0.1487\n",
      " 27/312 [=>............................] - ETA: 1:33 - loss: 2.7188 - acc: 0.1505\n",
      " 28/312 [=>............................] - ETA: 1:30 - loss: 2.6969 - acc: 0.1532\n",
      " 29/312 [=>............................] - ETA: 1:27 - loss: 2.6802 - acc: 0.1544\n",
      " 30/312 [=>............................] - ETA: 1:25 - loss: 2.6635 - acc: 0.1549\n",
      " 31/312 [=>............................] - ETA: 1:22 - loss: 2.6434 - acc: 0.1580\n",
      " 32/312 [==>...........................] - ETA: 1:20 - loss: 2.6243 - acc: 0.1606\n",
      " 33/312 [==>...........................] - ETA: 1:18 - loss: 2.6100 - acc: 0.1617\n",
      " 34/312 [==>...........................] - ETA: 1:16 - loss: 2.5950 - acc: 0.1641\n",
      " 35/312 [==>...........................] - ETA: 1:14 - loss: 2.5834 - acc: 0.1643\u001b[0m\n",
      "\u001b[31m 36/312 [==>...........................] - ETA: 1:12 - loss: 2.5748 - acc: 0.1638\n",
      " 37/312 [==>...........................] - ETA: 1:10 - loss: 2.5625 - acc: 0.1639\n",
      " 38/312 [==>...........................] - ETA: 1:08 - loss: 2.5497 - acc: 0.1661\n",
      " 39/312 [==>...........................] - ETA: 1:07 - loss: 2.5385 - acc: 0.1677\n",
      " 40/312 [==>...........................] - ETA: 1:05 - loss: 2.5271 - acc: 0.1684\n",
      " 41/312 [==>...........................] - ETA: 1:04 - loss: 2.5149 - acc: 0.1688\n",
      " 42/312 [===>..........................] - ETA: 1:03 - loss: 2.5042 - acc: 0.1689\n",
      " 43/312 [===>..........................] - ETA: 1:01 - loss: 2.4937 - acc: 0.1706\n",
      " 44/312 [===>..........................] - ETA: 1:00 - loss: 2.4842 - acc: 0.1715\n",
      " 45/312 [===>..........................] - ETA: 59s - loss: 2.4717 - acc: 0.1750 \n",
      " 46/312 [===>..........................] - ETA: 58s - loss: 2.4618 - acc: 0.1756\n",
      " 47/312 [===>..........................] - ETA: 57s - loss: 2.4524 - acc: 0.1770\n",
      " 48/312 [===>..........................] - ETA: 55s - loss: 2.4439 - acc: 0.1790\n",
      " 49/312 [===>..........................] - ETA: 54s - loss: 2.4351 - acc: 0.1800\n",
      " 50/312 [===>..........................] - ETA: 53s - loss: 2.4260 - acc: 0.1812\n",
      " 51/312 [===>..........................] - ETA: 53s - loss: 2.4174 - acc: 0.1828\u001b[0m\n",
      "\u001b[31m 52/312 [====>.........................] - ETA: 52s - loss: 2.4101 - acc: 0.1837\n",
      " 53/312 [====>.........................] - ETA: 51s - loss: 2.4016 - acc: 0.1859\n",
      " 54/312 [====>.........................] - ETA: 50s - loss: 2.3945 - acc: 0.1862\n",
      " 55/312 [====>.........................] - ETA: 49s - loss: 2.3877 - acc: 0.1875\n",
      " 56/312 [====>.........................] - ETA: 48s - loss: 2.3814 - acc: 0.1885\n",
      " 57/312 [====>.........................] - ETA: 47s - loss: 2.3739 - acc: 0.1900\n",
      " 58/312 [====>.........................] - ETA: 47s - loss: 2.3688 - acc: 0.1911\n",
      " 59/312 [====>.........................] - ETA: 46s - loss: 2.3616 - acc: 0.1923\n",
      " 60/312 [====>.........................] - ETA: 45s - loss: 2.3547 - acc: 0.1931\n",
      " 61/312 [====>.........................] - ETA: 45s - loss: 2.3481 - acc: 0.1944\n",
      " 62/312 [====>.........................] - ETA: 44s - loss: 2.3397 - acc: 0.1961\n",
      " 63/312 [=====>........................] - ETA: 43s - loss: 2.3336 - acc: 0.1970\n",
      " 64/312 [=====>........................] - ETA: 43s - loss: 2.3283 - acc: 0.1978\n",
      " 65/312 [=====>........................] - ETA: 42s - loss: 2.3206 - acc: 0.1998\n",
      " 66/312 [=====>........................] - ETA: 42s - loss: 2.3151 - acc: 0.2010\n",
      " 67/312 [=====>........................] - ETA: 41s - loss: 2.3121 - acc: 0.2009\u001b[0m\n",
      "\u001b[31m 68/312 [=====>........................] - ETA: 40s - loss: 2.3069 - acc: 0.2017\n",
      " 69/312 [=====>........................] - ETA: 40s - loss: 2.3012 - acc: 0.2027\n",
      " 70/312 [=====>........................] - ETA: 39s - loss: 2.2966 - acc: 0.2031\n",
      " 71/312 [=====>........................] - ETA: 39s - loss: 2.2929 - acc: 0.2030\n",
      " 72/312 [=====>........................] - ETA: 38s - loss: 2.2862 - acc: 0.2049\n",
      " 73/312 [======>.......................] - ETA: 38s - loss: 2.2816 - acc: 0.2053\n",
      " 74/312 [======>.......................] - ETA: 37s - loss: 2.2777 - acc: 0.2060\n",
      " 75/312 [======>.......................] - ETA: 37s - loss: 2.2722 - acc: 0.2072\n",
      " 76/312 [======>.......................] - ETA: 36s - loss: 2.2666 - acc: 0.2081\n",
      " 77/312 [======>.......................] - ETA: 36s - loss: 2.2602 - acc: 0.2095\n",
      " 78/312 [======>.......................] - ETA: 36s - loss: 2.2566 - acc: 0.2101\n",
      " 79/312 [======>.......................] - ETA: 35s - loss: 2.2550 - acc: 0.2103\n",
      " 80/312 [======>.......................] - ETA: 35s - loss: 2.2497 - acc: 0.2115\n",
      " 81/312 [======>.......................] - ETA: 34s - loss: 2.2471 - acc: 0.2114\n",
      " 82/312 [======>.......................] - ETA: 34s - loss: 2.2434 - acc: 0.2126\n",
      " 83/312 [======>.......................] - ETA: 34s - loss: 2.2398 - acc: 0.2132\n",
      " 84/312 [=======>......................] - ETA: 33s - loss: 2.2355 - acc: 0.2146\u001b[0m\n",
      "\u001b[31m 85/312 [=======>......................] - ETA: 33s - loss: 2.2322 - acc: 0.2149\n",
      " 86/312 [=======>......................] - ETA: 32s - loss: 2.2290 - acc: 0.2147\n",
      " 87/312 [=======>......................] - ETA: 32s - loss: 2.2249 - acc: 0.2155\n",
      " 88/312 [=======>......................] - ETA: 32s - loss: 2.2209 - acc: 0.2156\n",
      " 89/312 [=======>......................] - ETA: 31s - loss: 2.2166 - acc: 0.2166\n",
      " 90/312 [=======>......................] - ETA: 31s - loss: 2.2140 - acc: 0.2167\n",
      " 91/312 [=======>......................] - ETA: 31s - loss: 2.2109 - acc: 0.2167\n",
      " 92/312 [=======>......................] - ETA: 30s - loss: 2.2068 - acc: 0.2177\n",
      " 93/312 [=======>......................] - ETA: 30s - loss: 2.2019 - acc: 0.2192\n",
      " 94/312 [========>.....................] - ETA: 30s - loss: 2.1984 - acc: 0.2194\n",
      " 95/312 [========>.....................] - ETA: 29s - loss: 2.1949 - acc: 0.2197\n",
      " 96/312 [========>.....................] - ETA: 29s - loss: 2.1927 - acc: 0.2199\n",
      " 97/312 [========>.....................] - ETA: 29s - loss: 2.1890 - acc: 0.2208\n",
      " 98/312 [========>.....................] - ETA: 28s - loss: 2.1858 - acc: 0.2214\n",
      " 99/312 [========>.....................] - ETA: 28s - loss: 2.1834 - acc: 0.2220\u001b[0m\n",
      "\u001b[31m100/312 [========>.....................] - ETA: 28s - loss: 2.1811 - acc: 0.2230\u001b[0m\n",
      "\u001b[31m101/312 [========>.....................] - ETA: 28s - loss: 2.1765 - acc: 0.2236\u001b[0m\n",
      "\u001b[31m102/312 [========>.....................] - ETA: 27s - loss: 2.1739 - acc: 0.2238\u001b[0m\n",
      "\u001b[31m103/312 [========>.....................] - ETA: 27s - loss: 2.1718 - acc: 0.2245\u001b[0m\n",
      "\u001b[31m104/312 [=========>....................] - ETA: 27s - loss: 2.1684 - acc: 0.2253\u001b[0m\n",
      "\u001b[31m105/312 [=========>....................] - ETA: 26s - loss: 2.1654 - acc: 0.2260\u001b[0m\n",
      "\u001b[31m106/312 [=========>....................] - ETA: 26s - loss: 2.1633 - acc: 0.2262\u001b[0m\n",
      "\u001b[31m107/312 [=========>....................] - ETA: 26s - loss: 2.1594 - acc: 0.2269\u001b[0m\n",
      "\u001b[31m108/312 [=========>....................] - ETA: 26s - loss: 2.1555 - acc: 0.2279\u001b[0m\n",
      "\u001b[31m109/312 [=========>....................] - ETA: 25s - loss: 2.1530 - acc: 0.2288\u001b[0m\n",
      "\u001b[31m110/312 [=========>....................] - ETA: 25s - loss: 2.1494 - acc: 0.2295\u001b[0m\n",
      "\u001b[31m111/312 [=========>....................] - ETA: 25s - loss: 2.1478 - acc: 0.2294\u001b[0m\n",
      "\u001b[31m112/312 [=========>....................] - ETA: 25s - loss: 2.1440 - acc: 0.2308\u001b[0m\n",
      "\u001b[31m113/312 [=========>....................] - ETA: 24s - loss: 2.1413 - acc: 0.2311\u001b[0m\n",
      "\u001b[31m114/312 [=========>....................] - ETA: 24s - loss: 2.1378 - acc: 0.2320\u001b[0m\n",
      "\u001b[31m115/312 [==========>...................] - ETA: 24s - loss: 2.1345 - acc: 0.2332\u001b[0m\n",
      "\u001b[31m116/312 [==========>...................] - ETA: 24s - loss: 2.1304 - acc: 0.2344\u001b[0m\n",
      "\u001b[31m117/312 [==========>...................] - ETA: 23s - loss: 2.1289 - acc: 0.2344\u001b[0m\n",
      "\u001b[31m118/312 [==========>...................] - ETA: 23s - loss: 2.1253 - acc: 0.2352\u001b[0m\n",
      "\u001b[31m119/312 [==========>...................] - ETA: 23s - loss: 2.1223 - acc: 0.2358\u001b[0m\n",
      "\u001b[31m120/312 [==========>...................] - ETA: 23s - loss: 2.1198 - acc: 0.2365\u001b[0m\n",
      "\u001b[31m121/312 [==========>...................] - ETA: 23s - loss: 2.1175 - acc: 0.2373\u001b[0m\n",
      "\u001b[31m122/312 [==========>...................] - ETA: 22s - loss: 2.1153 - acc: 0.2378\u001b[0m\n",
      "\u001b[31m123/312 [==========>...................] - ETA: 22s - loss: 2.1128 - acc: 0.2380\u001b[0m\n",
      "\u001b[31m124/312 [==========>...................] - ETA: 22s - loss: 2.1103 - acc: 0.2385\u001b[0m\n",
      "\u001b[31m125/312 [===========>..................] - ETA: 22s - loss: 2.1091 - acc: 0.2389\u001b[0m\n",
      "\u001b[31m126/312 [===========>..................] - ETA: 22s - loss: 2.1059 - acc: 0.2398\u001b[0m\n",
      "\u001b[31m127/312 [===========>..................] - ETA: 21s - loss: 2.1031 - acc: 0.2405\u001b[0m\n",
      "\u001b[31m128/312 [===========>..................] - ETA: 21s - loss: 2.1006 - acc: 0.2412\u001b[0m\n",
      "\u001b[31m129/312 [===========>..................] - ETA: 21s - loss: 2.0980 - acc: 0.2422\u001b[0m\n",
      "\u001b[31m130/312 [===========>..................] - ETA: 21s - loss: 2.0960 - acc: 0.2427\u001b[0m\n",
      "\u001b[31m131/312 [===========>..................] - ETA: 21s - loss: 2.0934 - acc: 0.2436\u001b[0m\n",
      "\u001b[31m132/312 [===========>..................] - ETA: 20s - loss: 2.0920 - acc: 0.2440\u001b[0m\n",
      "\u001b[31m133/312 [===========>..................] - ETA: 20s - loss: 2.0900 - acc: 0.2442\u001b[0m\n",
      "\u001b[31m134/312 [===========>..................] - ETA: 20s - loss: 2.0875 - acc: 0.2448\u001b[0m\n",
      "\u001b[31m135/312 [===========>..................] - ETA: 20s - loss: 2.0858 - acc: 0.2453\u001b[0m\n",
      "\u001b[31m136/312 [============>.................] - ETA: 20s - loss: 2.0840 - acc: 0.2457\u001b[0m\n",
      "\u001b[31m137/312 [============>.................] - ETA: 19s - loss: 2.0828 - acc: 0.2459\u001b[0m\n",
      "\u001b[31m138/312 [============>.................] - ETA: 19s - loss: 2.0804 - acc: 0.2463\u001b[0m\n",
      "\u001b[31m139/312 [============>.................] - ETA: 19s - loss: 2.0783 - acc: 0.2466\u001b[0m\n",
      "\u001b[31m140/312 [============>.................] - ETA: 19s - loss: 2.0756 - acc: 0.2474\u001b[0m\n",
      "\u001b[31m141/312 [============>.................] - ETA: 19s - loss: 2.0732 - acc: 0.2478\u001b[0m\n",
      "\u001b[31m142/312 [============>.................] - ETA: 19s - loss: 2.0701 - acc: 0.2483\u001b[0m\n",
      "\u001b[31m143/312 [============>.................] - ETA: 18s - loss: 2.0677 - acc: 0.2487\u001b[0m\n",
      "\u001b[31m144/312 [============>.................] - ETA: 18s - loss: 2.0656 - acc: 0.2491\u001b[0m\n",
      "\u001b[31m145/312 [============>.................] - ETA: 18s - loss: 2.0634 - acc: 0.2493\u001b[0m\n",
      "\u001b[31m146/312 [=============>................] - ETA: 18s - loss: 2.0615 - acc: 0.2501\u001b[0m\n",
      "\u001b[31m147/312 [=============>................] - ETA: 18s - loss: 2.0591 - acc: 0.2511\u001b[0m\n",
      "\u001b[31m148/312 [=============>................] - ETA: 18s - loss: 2.0565 - acc: 0.2518\u001b[0m\n",
      "\u001b[31m149/312 [=============>................] - ETA: 17s - loss: 2.0547 - acc: 0.2525\u001b[0m\n",
      "\u001b[31m150/312 [=============>................] - ETA: 17s - loss: 2.0530 - acc: 0.2529\u001b[0m\n",
      "\u001b[31m151/312 [=============>................] - ETA: 17s - loss: 2.0512 - acc: 0.2532\u001b[0m\n",
      "\u001b[31m152/312 [=============>................] - ETA: 17s - loss: 2.0497 - acc: 0.2530\u001b[0m\n",
      "\u001b[31m153/312 [=============>................] - ETA: 17s - loss: 2.0479 - acc: 0.2539\u001b[0m\n",
      "\u001b[31m155/312 [=============>................] - ETA: 16s - loss: 2.0439 - acc: 0.2547\u001b[0m\n",
      "\u001b[31m157/312 [==============>...............] - ETA: 16s - loss: 2.0391 - acc: 0.2554\u001b[0m\n",
      "\u001b[31m159/312 [==============>...............] - ETA: 16s - loss: 2.0353 - acc: 0.2562\u001b[0m\n",
      "\u001b[31m161/312 [==============>...............] - ETA: 15s - loss: 2.0318 - acc: 0.2570\u001b[0m\n",
      "\u001b[31m163/312 [==============>...............] - ETA: 15s - loss: 2.0267 - acc: 0.2592\u001b[0m\n",
      "\u001b[31m165/312 [==============>...............] - ETA: 15s - loss: 2.0219 - acc: 0.2608\u001b[0m\n",
      "\u001b[31m167/312 [===============>..............] - ETA: 14s - loss: 2.0185 - acc: 0.2616\u001b[0m\n",
      "\u001b[31m169/312 [===============>..............] - ETA: 14s - loss: 2.0150 - acc: 0.2627\u001b[0m\n",
      "\u001b[31m171/312 [===============>..............] - ETA: 14s - loss: 2.0121 - acc: 0.2635\u001b[0m\n",
      "\u001b[31m173/312 [===============>..............] - ETA: 13s - loss: 2.0099 - acc: 0.2638\u001b[0m\n",
      "\u001b[31m175/312 [===============>..............] - ETA: 13s - loss: 2.0064 - acc: 0.2646\u001b[0m\n",
      "\u001b[31m177/312 [================>.............] - ETA: 13s - loss: 2.0037 - acc: 0.2657\u001b[0m\n",
      "\u001b[31m179/312 [================>.............] - ETA: 13s - loss: 2.0007 - acc: 0.2665\u001b[0m\n",
      "\u001b[31m181/312 [================>.............] - ETA: 12s - loss: 1.9969 - acc: 0.2673\u001b[0m\n",
      "\u001b[31m183/312 [================>.............] - ETA: 12s - loss: 1.9931 - acc: 0.2687\u001b[0m\n",
      "\u001b[31m185/312 [================>.............] - ETA: 12s - loss: 1.9902 - acc: 0.2695\u001b[0m\n",
      "\u001b[31m187/312 [================>.............] - ETA: 11s - loss: 1.9871 - acc: 0.2705\u001b[0m\n",
      "\u001b[31m189/312 [=================>............] - ETA: 11s - loss: 1.9847 - acc: 0.2713\u001b[0m\n",
      "\u001b[31m191/312 [=================>............] - ETA: 11s - loss: 1.9820 - acc: 0.2723\u001b[0m\n",
      "\u001b[31m193/312 [=================>............] - ETA: 11s - loss: 1.9784 - acc: 0.2737\u001b[0m\n",
      "\u001b[31m195/312 [=================>............] - ETA: 10s - loss: 1.9757 - acc: 0.2745\u001b[0m\n",
      "\u001b[31m197/312 [=================>............] - ETA: 10s - loss: 1.9723 - acc: 0.2755\u001b[0m\n",
      "\u001b[31m199/312 [==================>...........] - ETA: 10s - loss: 1.9699 - acc: 0.2761\u001b[0m\n",
      "\u001b[31m201/312 [==================>...........] - ETA: 10s - loss: 1.9669 - acc: 0.2774\u001b[0m\n",
      "\u001b[31m203/312 [==================>...........] - ETA: 9s - loss: 1.9638 - acc: 0.2779 \u001b[0m\n",
      "\u001b[31m205/312 [==================>...........] - ETA: 9s - loss: 1.9603 - acc: 0.2787\u001b[0m\n",
      "\u001b[31m207/312 [==================>...........] - ETA: 9s - loss: 1.9582 - acc: 0.2793\u001b[0m\n",
      "\u001b[31m209/312 [===================>..........] - ETA: 9s - loss: 1.9570 - acc: 0.2801\u001b[0m\n",
      "\u001b[31m211/312 [===================>..........] - ETA: 9s - loss: 1.9531 - acc: 0.2812\u001b[0m\n",
      "\u001b[31m213/312 [===================>..........] - ETA: 8s - loss: 1.9507 - acc: 0.2818\u001b[0m\n",
      "\u001b[31m215/312 [===================>..........] - ETA: 8s - loss: 1.9487 - acc: 0.2823\u001b[0m\n",
      "\u001b[31m217/312 [===================>..........] - ETA: 8s - loss: 1.9453 - acc: 0.2831\u001b[0m\n",
      "\u001b[31m219/312 [====================>.........] - ETA: 8s - loss: 1.9432 - acc: 0.2837\u001b[0m\n",
      "\u001b[31m221/312 [====================>.........] - ETA: 7s - loss: 1.9420 - acc: 0.2843\u001b[0m\n",
      "\u001b[31m223/312 [====================>.........] - ETA: 7s - loss: 1.9395 - acc: 0.2853\u001b[0m\n",
      "\u001b[31m225/312 [====================>.........] - ETA: 7s - loss: 1.9370 - acc: 0.2860\u001b[0m\n",
      "\u001b[31m227/312 [====================>.........] - ETA: 7s - loss: 1.9351 - acc: 0.2867\u001b[0m\n",
      "\u001b[31m229/312 [=====================>........] - ETA: 7s - loss: 1.9333 - acc: 0.2869\u001b[0m\n",
      "\u001b[31m231/312 [=====================>........] - ETA: 6s - loss: 1.9314 - acc: 0.2879\u001b[0m\n",
      "\u001b[31m233/312 [=====================>........] - ETA: 6s - loss: 1.9296 - acc: 0.2884\u001b[0m\n",
      "\u001b[31m235/312 [=====================>........] - ETA: 6s - loss: 1.9267 - acc: 0.2899\u001b[0m\n",
      "\u001b[31m237/312 [=====================>........] - ETA: 6s - loss: 1.9252 - acc: 0.2904\u001b[0m\n",
      "\u001b[31m239/312 [=====================>........] - ETA: 6s - loss: 1.9224 - acc: 0.2913\u001b[0m\n",
      "\u001b[31m241/312 [======================>.......] - ETA: 5s - loss: 1.9213 - acc: 0.2918\u001b[0m\n",
      "\u001b[31m243/312 [======================>.......] - ETA: 5s - loss: 1.9196 - acc: 0.2922\u001b[0m\n",
      "\u001b[31m245/312 [======================>.......] - ETA: 5s - loss: 1.9172 - acc: 0.2930\u001b[0m\n",
      "\u001b[31m247/312 [======================>.......] - ETA: 5s - loss: 1.9151 - acc: 0.2938\u001b[0m\n",
      "\u001b[31m249/312 [======================>.......] - ETA: 5s - loss: 1.9127 - acc: 0.2942\u001b[0m\n",
      "\u001b[31m251/312 [=======================>......] - ETA: 4s - loss: 1.9104 - acc: 0.2949\u001b[0m\n",
      "\u001b[31m253/312 [=======================>......] - ETA: 4s - loss: 1.9083 - acc: 0.2957\u001b[0m\n",
      "\u001b[31m255/312 [=======================>......] - ETA: 4s - loss: 1.9063 - acc: 0.2966\u001b[0m\n",
      "\u001b[31m257/312 [=======================>......] - ETA: 4s - loss: 1.9038 - acc: 0.2970\u001b[0m\n",
      "\u001b[31m259/312 [=======================>......] - ETA: 4s - loss: 1.9018 - acc: 0.2973\u001b[0m\n",
      "\u001b[31m261/312 [========================>.....] - ETA: 4s - loss: 1.8997 - acc: 0.2981\u001b[0m\n",
      "\u001b[31m263/312 [========================>.....] - ETA: 3s - loss: 1.8979 - acc: 0.2991\u001b[0m\n",
      "\u001b[31m265/312 [========================>.....] - ETA: 3s - loss: 1.8958 - acc: 0.2995\u001b[0m\n",
      "\u001b[31m267/312 [========================>.....] - ETA: 3s - loss: 1.8933 - acc: 0.3004\u001b[0m\n",
      "\u001b[31m269/312 [========================>.....] - ETA: 3s - loss: 1.8909 - acc: 0.3014\u001b[0m\n",
      "\u001b[31m271/312 [=========================>....] - ETA: 3s - loss: 1.8886 - acc: 0.3021\u001b[0m\n",
      "\u001b[31m273/312 [=========================>....] - ETA: 3s - loss: 1.8855 - acc: 0.3031\u001b[0m\n",
      "\u001b[31m275/312 [=========================>....] - ETA: 2s - loss: 1.8837 - acc: 0.3035\u001b[0m\n",
      "\u001b[31m277/312 [=========================>....] - ETA: 2s - loss: 1.8823 - acc: 0.3040\u001b[0m\n",
      "\u001b[31m279/312 [=========================>....] - ETA: 2s - loss: 1.8800 - acc: 0.3047\u001b[0m\n",
      "\u001b[31m281/312 [==========================>...] - ETA: 2s - loss: 1.8780 - acc: 0.3049\u001b[0m\n",
      "\u001b[31m283/312 [==========================>...] - ETA: 2s - loss: 1.8762 - acc: 0.3057\u001b[0m\n",
      "\u001b[31m285/312 [==========================>...] - ETA: 2s - loss: 1.8751 - acc: 0.3063\u001b[0m\n",
      "\u001b[31m287/312 [==========================>...] - ETA: 1s - loss: 1.8733 - acc: 0.3068\u001b[0m\n",
      "\u001b[31m289/312 [==========================>...] - ETA: 1s - loss: 1.8719 - acc: 0.3074\u001b[0m\n",
      "\u001b[31m291/312 [==========================>...] - ETA: 1s - loss: 1.8704 - acc: 0.3078\u001b[0m\n",
      "\u001b[31m293/312 [===========================>..] - ETA: 1s - loss: 1.8681 - acc: 0.3088\u001b[0m\n",
      "\u001b[31m295/312 [===========================>..] - ETA: 1s - loss: 1.8666 - acc: 0.3092\u001b[0m\n",
      "\u001b[31m297/312 [===========================>..] - ETA: 1s - loss: 1.8650 - acc: 0.3098\u001b[0m\n",
      "\u001b[31m299/312 [===========================>..] - ETA: 0s - loss: 1.8635 - acc: 0.3104\u001b[0m\n",
      "\u001b[31m301/312 [===========================>..] - ETA: 0s - loss: 1.8614 - acc: 0.3113\u001b[0m\n",
      "\u001b[31m303/312 [============================>.] - ETA: 0s - loss: 1.8597 - acc: 0.3119\u001b[0m\n",
      "\u001b[31m305/312 [============================>.] - ETA: 0s - loss: 1.8584 - acc: 0.3124\u001b[0m\n",
      "\u001b[31m307/312 [============================>.] - ETA: 0s - loss: 1.8568 - acc: 0.3130\u001b[0m\n",
      "\u001b[31m309/312 [============================>.] - ETA: 0s - loss: 1.8556 - acc: 0.3136\u001b[0m\n",
      "\u001b[31m311/312 [============================>.] - ETA: 0s - loss: 1.8537 - acc: 0.3144\u001b[0m\n",
      "\u001b[31m312/312 [==============================] - 25s 81ms/step - loss: 1.8530 - acc: 0.3148 - val_loss: 3.5104 - val_acc: 0.1411\u001b[0m\n",
      "\n",
      "2019-10-01 02:28:32 Uploading - Uploading generated training model\n",
      "2019-10-01 02:28:32 Completed - Training job completed\n",
      "\u001b[31mINFO:root:Test loss:3.4707719698930397\u001b[0m\n",
      "\u001b[31mINFO:root:Test accuracy:0.14252804487179488\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[31mINFO:root:Model successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[31m2019-10-01 02:28:24,625 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Billable seconds: <time>\n",
    "```\n",
    "\n",
    "と出力されればトレーニング終了です。これが実際にトレーニングインスタンスが課金される時間となります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
